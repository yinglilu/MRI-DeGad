{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/fogunsan.5672212.0/tmp/kslurm-venv-7yr1gtes/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "import time\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    Spacingd,\n",
    "    RandWeightedCrop,\n",
    "    RandRotate,\n",
    "    Rand3DElasticd,\n",
    "    RandRotated,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityd,\n",
    "    RandFlipd)\n",
    "import tqdm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, Dataset ,nifti_saver, PatchDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "from glob import glob\n",
    "from monai.networks.blocks import Convolution\n",
    "from monai.networks.nets import Discriminator, Generator\n",
    "from monai.utils import progress_bar\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader \n",
    "import torchmetrics #need to download torchmetrics for CNN, so just gonna continue editing gan script and then run a kbatch script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gad_t1= sorted(glob('/home/fogunsan/scratch/degad/derivatives/passing_dataset/*/*_acq-gad_resampled_T1w.nii.gz'))# gad images who's corresponding nongad images underwent a rigid transform\n",
    "nongad_t1= sorted(glob('/home/fogunsan/scratch/degad/derivatives/normalized_fcm/*/*_acq-nongad_normalized_fcm.nii.gz')) # nongad images which underwent a rigid transform and underwent fcm normalization\n",
    "image_dict = [{\"image\": gad_name, \"label\": nongad_name} for gad_name, nongad_name in zip(gad_t1,nongad_t1)] #creates list of dictionaries, with gad and nongad images labelled\n",
    "train_files, test_files = image_dict[0:2], image_dict[38:] #creates a list of dictionaries for each set (training, val, testing), with keys of gad and nongad in each index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "num_train_files = len(train_files)\n",
    "num_patches = 20#patches per image\n",
    "batch_size = 10\n",
    "training_sample_size = int(num_train_files * num_patches / batch_size)\n",
    "\n",
    "load_images= Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityd(keys = [\"image\"], minv=0.0, maxv=1.0)])# applying min max normalization only on gad images\n",
    " \n",
    "train_imgs_cache = CacheDataset(data=train_files, transform=load_images)\n",
    "\n",
    "patching_func= RandCropByPosNegLabeld( # gonna use this function to create patches\n",
    "            keys = [\"image\", \"label\"],\n",
    "            label_key = \"image\",\n",
    "            spatial_size=(32,32,32),\n",
    "            pos = 1,\n",
    "            neg = 0.0001, # much larger probability of sampling foreground\n",
    "            num_samples= num_patches# CHANGE BACK TO 5000\n",
    "        )\n",
    "patch_transforms = Compose([RandRotated(keys =[\"image\", \"label\"], range_x = [0.8,0.8], range_y = [0.8,0.8], range_z = [0.8,0.8], prob = 0.4), RandFlipd(keys =[\"image\", \"label\"], prob = 0.2, spatial_axis=1)])# flipping along y-axis (horizontally)\n",
    "train_patches_dataset = PatchDataset(data = train_imgs_cache, patch_func=patching_func, samples_per_image=num_patches, transform = patch_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "Generator=UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            channels=(16, 32,64,128,256,512,512,512),\n",
    "            strides=(2, 2, 2, 2,1,1,1),\n",
    "            dropout= 0.2,\n",
    "        )\n",
    "gen = Generator\n",
    "gen.apply(monai.networks.normal_init)\n",
    "gen_model = gen.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GANDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 64, kernel_size, stride=2, padding=1),\n",
    "            nn.InstanceNorm3d(64),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, kernel_size, stride=2, padding=1),\n",
    "            nn.InstanceNorm3d(128),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(128, 256, kernel_size, stride=2, padding=1),\n",
    "            nn.InstanceNorm3d(256),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv_out = nn.Conv3d(256, 1, kernel_size, stride=1, padding=0)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.tanh(x)\n",
    "        return x\n",
    "disc = GANDiscriminator()\n",
    "disc.apply(monai.networks.normal_init)\n",
    "disc_model = disc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GeneratorLoss(nongad_images,degad_images, fake_preds):\n",
    "    \"\"\"\n",
    "    Loss function is the sum of the binary cross entropy between the error of the discriminator output btwn gad and degad (fake prediction) and the root mean square error betwn as nongad and degad images multiplies by scalar weight coefficient\n",
    "    nongad_image= real nongad images from the sample\n",
    "    degad_images= generated nongad images from the generator\n",
    "    fake_preds: output of discriminator when fed fake data\n",
    "    \"\"\"\n",
    "    \n",
    "    coeff = 0.01\n",
    "    \n",
    "    BCE_loss= torch.nn.BCELoss() \n",
    "    real_target = torch.ones((fake_preds.shape[0], fake_preds.shape[1], fake_preds.shape[2], fake_preds.shape[3], fake_preds.shape[4])) #new_full returns a tensor filled with 1 with the same shape as the discrminator prediction \n",
    "    fake_preds = torch.sigmoid(fake_preds) # applying sigmmoid function to output of the discriminator to map probability between 0 and 1\n",
    "    BCE_fake = BCE_loss(fake_preds.to(device), real_target.to(device)) # BCE loss btwn the output of discrim when fed fake data and 1 <- generator wants to minimize this\n",
    "    L1_loss = torch.nn.L1Loss()\n",
    "    loss = L1_loss(degad_images, nongad_images)  # producing RMSE between ground truth nongad and degad\n",
    "    generator_loss = loss*coeff + BCE_fake\n",
    "    return generator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DiscriminatorLoss(real_preds, fake_preds):\n",
    "    \"\"\"\n",
    "    Loss function for the discriminator: The discriminator loss is calculated by taking the sum of the L2 error of the discriminator output btwn gad and nongad( real prediction ) and the L2 error of the output btwn gad and degad( fake predition)\n",
    "    \n",
    "    real_preds: output of discriminator when fed real data\n",
    "    fake_preds: output of discriminator when fed fake data\n",
    "    \"\"\"\n",
    "    \n",
    "    real_target = torch.ones((real_preds.shape[0], real_preds.shape[1], real_preds.shape[2],real_preds.shape[3], real_preds.shape[4])) #new_full returns a tensor filled with 1 with the same shape as the discrminator prediction \n",
    "    \n",
    "    fake_target = torch.zeros((fake_preds.shape[0], fake_preds.shape[1], fake_preds.shape[2], fake_preds.shape[3], fake_preds.shape[4])) #new_full returns a tensor filled with 0 w/ the same shape as the generator prediction\n",
    "    BCE_loss =  torch.nn.BCELoss().to(device)  # creates a losss value for each batch, averaging the value across all elements\n",
    "    # Apply sigmoid to discriminator outputs, to fit between 0 and 1\n",
    "    real_preds = torch.sigmoid(real_preds).cuda()\n",
    "    fake_preds = torch.sigmoid(fake_preds).cuda()\n",
    "    \n",
    "    BCE_fake = BCE_loss(fake_preds.cuda(), fake_target.cuda()) # BCE loss btwn the output of discrim when fed fake data and 0 <- generator wants to minimize this\n",
    "    BCE_real = BCE_loss(real_preds.cuda(), real_target.cuda()) # BCE loss btwn the output of discrim when fed real data and 1 <- generator wants to minimize this\n",
    "    \n",
    "    return BCE_real + BCE_fake\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading dataloader\n",
      "1/4 epoch 1, avg gen loss: 0.0000, avg disc loss: 0.0000 [=======                       ]\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m disc_fake_pred \u001b[38;5;241m=\u001b[39m disc_model(torch\u001b[38;5;241m.\u001b[39mcat([gad_images, degad_images], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# getting disc losses when fed fake images\u001b[39;00m\n\u001b[1;32m     44\u001b[0m disc_loss \u001b[38;5;241m=\u001b[39m DiscriminatorLoss(disc_real_pred,disc_fake_pred)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mdisc_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#compute gradient of current tensor retain graph ensures each successive graph will take\u001b[39;00m\n\u001b[1;32m     48\u001b[0m disc_opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     50\u001b[0m disc_epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m disc_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# taking average of disc loss over the number of steps for this batch\u001b[39;00m\n",
      "File \u001b[0;32m/local/fogunsan.5672212.0/tmp/kslurm-venv-7yr1gtes/lib/python3.10/site-packages/torch/_tensor.py:479\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/local/fogunsan.5672212.0/tmp/kslurm-venv-7yr1gtes/lib/python3.10/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1530\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/local/fogunsan.5672212.0/tmp/kslurm-venv-7yr1gtes/lib/python3.10/site-packages/monai/data/meta_tensor.py:268\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 268\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m/local/fogunsan.5672212.0/tmp/kslurm-venv-7yr1gtes/lib/python3.10/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/local/fogunsan.5672212.0/tmp/kslurm-venv-7yr1gtes/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/fogunsan.5672212.0/tmp/kslurm-venv-7yr1gtes/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "learning_rate = 2e-4\n",
    "betas = (0.5, 0.999)\n",
    "gen_opt = torch.optim.Adam(gen_model.parameters(), lr = learning_rate, betas=betas)\n",
    "disc_opt = torch.optim.Adam(disc_model.parameters(), lr = learning_rate, betas=betas)\n",
    "\n",
    "epoch_loss_values = [0] # list of generator  loss calculated at the end of each epoch\n",
    "disc_loss_values = [0] # list of discriminator loss values calculated at end of each epoch\n",
    "\n",
    "disc_train_steps = 10 # number of times to loop thru discriminator for each batch\n",
    "max_epochs = 2\n",
    "start = time.time()\n",
    "\n",
    "train_loader = DataLoader(train_patches_dataset, batch_size=batch_size, shuffle=True)\n",
    "print('finished loading dataloader')\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    gen_model.train()\n",
    "    disc_model.train()# setting models to training mode\n",
    "    epoch_loss = 0 # initializing epoch loss for generator\n",
    "    disc_epoch_loss = 0 # initializing discriminator epoch loss\n",
    "    for i,train_batch in enumerate(train_loader):# iterating through dataloader\n",
    "        progress_bar(\n",
    "            index = i+1,\n",
    "            count = training_sample_size, \n",
    "            desc = f\"epoch {epoch + 1}, avg gen loss: {epoch_loss_values[-1]:.4f}, avg disc loss: {disc_loss_values[-1]:.4f}\",\n",
    "        )\n",
    "        gad_images =train_batch[\"image\"].cuda()# initial gad image of batch\n",
    "        nongad_images = train_batch[\"label\"].cuda() # initial nongad image of batch that i plan on concatenating onto since bug with batch function in monai\n",
    "        degad_images = gen_model(gad_images) # feeding CNN with gad images\n",
    "        disc_real_pred = disc_model(torch.cat([gad_images, nongad_images], dim=1))\n",
    "        disc_fake_pred = disc_model(torch.cat([gad_images, degad_images], dim=1)) # getting disc losses when fed fake images\n",
    "        \n",
    "        gen_loss = GeneratorLoss(nongad_images, degad_images, disc_fake_pred) # getting generator losses\n",
    "        gen_loss.backward()# computes gradient(derivative) of current tensor, automatically frees part of greaph that creates loss\n",
    "        gen_opt.step() # updates parameters to minimize loss\n",
    "        gen_opt.zero_grad()\n",
    "        epoch_loss += gen_loss.item()\n",
    "        \n",
    "        for _ in range(disc_train_steps):\n",
    "            disc_opt.zero_grad() # resetting gradient for discrmintor to 0\n",
    "            disc_real_pred = disc_model(torch.cat([gad_images, nongad_images], dim=1))\n",
    "            \n",
    "            disc_fake_pred = disc_model(torch.cat([gad_images, degad_images], dim=1)) # getting disc losses when fed fake images\n",
    "            disc_loss = DiscriminatorLoss(disc_real_pred,disc_fake_pred)\n",
    "            \n",
    "            disc_loss.backward() #compute gradient of current tensor retain graph ensures each successive graph will take\n",
    "            \n",
    "            disc_opt.step()\n",
    "            \n",
    "            disc_epoch_loss += disc_loss.item() # taking average of disc loss over the number of steps for this batch\n",
    "        disc_epoch_loss+=disc_total_loss # taking total disc loss over the total number of samples and over the 10 disc steps\n",
    "    \n",
    "    epoch_loss = epoch_loss / training_sample_size # epoch loss is the total loss by the end of that epoch divided by the number of steps\n",
    "    epoch_loss_values.append(epoch_loss) #updates the loss value for that epoch\n",
    "    disc_loss_values.append(disc_epoch_loss / (10*training_sample_size)) # total disc loss is the total loss divided by the total disc steps in the epoch\n",
    "end = time.time()\n",
    "time = end - start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('/home/fogunsan/scratch/degad/derivatives/GAN_network/April21/model_stats.txt', 'w') as file:  \n",
    "    file.write(f'training time: {time} \\n')  \n",
    "    file.write(f'generator loss: {epoch_loss_values[-1]} discriminator loss: {disc_loss_values[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################Saving trained generator and discriminator networks\n",
    "\n",
    "torch.save(gen_model.state_dict(), \"/home/fogunsan/scratch/degad/derivatives/GAN_network/April21/trained_generator.pt\")\n",
    "torch.save(disc_model.state_dict(), \"/home/fogunsan/scratch/degad/derivatives/GAN_network/April21/trained_discriminator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.semilogy(*zip(*gen_step_loss), label=\"Generator Loss\")\n",
    "plt.semilogy(*zip(*disc_step_loss), label=\"Discriminator Loss\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "plt.savefig('/home/ROBARTS/fogunsanya/graham/scratch/degad/derivatives/GAN_network/April21/lossfunctions.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
