{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    Spacingd,\n",
    "    RandWeightedCrop,\n",
    "    RandRotate,\n",
    "    RandFlip,\n",
    "    Rand3DElasticd,\n",
    "    RandRotated,\n",
    "    LoadImage,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureChannelFirst,\n",
    "    ScaleIntensityd,\n",
    "    ScaleIntensity,\n",
    "    RandFlipd)\n",
    "import shutil\n",
    "import tqdm\n",
    "from torchmetrics import MeanSquaredError\n",
    "import time\n",
    "from monai.networks.nets import UNet\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, Dataset ,nifti_saver, PatchDataset, DataLoader, PersistentDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "from glob import glob\n",
    "from monai.networks.blocks import Convolution\n",
    "from monai.networks.nets import Discriminator, Generator\n",
    "from monai.utils import progress_bar\n",
    "import torch.nn as nn\n",
    "import torchmetrics \n",
    "from pytorchtools import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gad_t1= sorted(glob('/home/fogunsan/scratch/degad/derivatives/passing_dataset/*/*_acq-gad_resampled_T1w.nii.gz'))# gad images who's corresponding nongad images underwent a rigid transform\n",
    "nongad_t1= sorted(glob('/home/fogunsan/scratch/degad/derivatives/normalized_fcm/*/*_acq-nongad_normalized_fcm.nii.gz')) # nongad images which underwent a rigid transform and underwent fcm normalization\n",
    "image_dict = [{\"image\": gad_name, \"label\": nongad_name} for gad_name, nongad_name in zip(gad_t1,nongad_t1)] #creates list of dictionaries, with gad and nongad images labelled\n",
    "print(len(image_dict))\n",
    "train_files, validate_files, test_files = (image_dict[0:30] + image_dict[36:41:2]),(image_dict[30:36] + image_dict[37:42:2]), image_dict[42:47] #creates a list of dictionaries for each set (training, val, testing), with keys of gad and nongad in each index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now caching before and after patching\n",
    "num_train_files = len(train_files)\n",
    "num_validate_files = len(validate_files)\n",
    "num_patches =1200 #patches per image\n",
    "batch_size = 5\n",
    "date = \"May30\" # set to current day to not overwrite previous models\n",
    "training_steps = int(num_train_files * num_patches / batch_size) # number of training steps per epoch\n",
    "validation_steps = int(num_validate_files * num_patches / batch_size) # number of validation steps per epoch\n",
    "load_images= Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityd(keys = [\"image\"], minv=0.0, maxv=1.0)])# applying min max normalization only on gad images\n",
    "    \n",
    "train_imgs_cache = CacheDataset(data=train_files, transform=load_images, cache_rate=1.0, num_workers = 1) # dataset with cache mechanism that can load data and cache deterministic transforms’ result during training.\n",
    "validate_imgs_cache = CacheDataset(data=validate_files, transform=load_images, cache_rate=1.0,num_workers =1)\n",
    "\n",
    "patching_func= RandCropByPosNegLabeld(# gonna use this function to create patches\n",
    "            keys = [\"image\", \"label\"],\n",
    "            label_key = \"image\",\n",
    "            spatial_size=(32,32,32),\n",
    "            pos = 1,\n",
    "            neg = 0.01, # 1\n",
    "            num_samples= num_patches# CHANGE BACK TO 5000\n",
    "        )\n",
    "patch_transforms = Compose([\n",
    "    RandRotated(keys =[\"image\", \"label\"], range_x = 0.8, range_y = 0.8, range_z = 0.8, prob = 0.4), \n",
    "    RandFlipd(keys =[\"image\", \"label\"], prob = 0.2, spatial_axis=1)])\n",
    "   # Rand3DElasticd(keys =[\"image\", \"label\"], sigma_range = (0.5,1), magnitude_range = (0.1, 0.3), prob=0.3, shear_range=[0.1, -0.05, 0.0, 0.0, 0.0, 0.0], scale_range=0.5, padding_mode= \"zeros\")\n",
    "# flipping along y-axis (horizontally), using small SD range for blurring kernel for the warp, \n",
    "train_patches_dataset = PatchDataset(data = train_imgs_cache, patch_func=patching_func, samples_per_image=num_patches, transform= patch_transforms)\n",
    "validate_patches_dataset = PatchDataset(data = validate_imgs_cache, patch_func=patching_func, samples_per_image=num_patches) \n",
    "\n",
    "train_patches_dataset = CacheDataset(data=train_patches_dataset,cache_rate=1.0, num_workers =1, copy_cache= False) # dataset with cache mechanism that can load data and cache deterministic transforms’ result during training.\n",
    "validate_patches_dataset = CacheDataset(data=validate_patches_dataset, cache_rate=1.0, num_workers =1, copy_cache=False)\n",
    "#setting num_workers >1 causes transforms error later on in training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN=UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            channels=(16, 32,64,128,256,512,512,512),\n",
    "            strides=(2, 2, 2, 2,1,1,1),\n",
    "            dropout= 0.2,\n",
    "        )\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "CNN.apply(monai.networks.normal_init)\n",
    "CNN_model = CNN.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "learning_rate = 2e-5 # changed from 2e-4\n",
    "betas = (0.5, 0.999)\n",
    "cnn_opt = torch.optim.Adam(CNN_model.parameters(), lr = learning_rate, betas=betas)\n",
    "\n",
    "patience = 100# epochs it will take for training to terminate if no improvement\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True, path = f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/checkpoint.pt')\n",
    "start = time.time() # initializing variable to calculate training time\n",
    "\n",
    "max_epochs = 4000 # max total iterations over entire training set\n",
    "#root_mean_squared = MeanSquaredError(squared = False).to(device) #rmse metric calculated at the end of each epoch for training and val\n",
    "mean_abs_error = torch.nn.L1Loss().to(device)\n",
    "\n",
    "mae_val = [0] # list of validation loss calculated at the end of each epoch\n",
    "epoch_loss_values = [0] # list of training loss calculated at the end of each epoch\n",
    "\n",
    "train_loader = DataLoader(train_patches_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validate_patches_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    CNN_model.train() # setting model to training mode\n",
    "    epoch_loss = 0 # total traininig loss in an epoch\n",
    "    progress_bar(\n",
    "            index=epoch+1, # displays what step we are of current epoch, our epoch number, training  loss\n",
    "            count = max_epochs, \n",
    "            desc= f\"epoch {epoch + 1}, training mae loss: {epoch_loss_values[-1]:.4f}, validation mae metric: {mae_val[-1]:.4f}\",\n",
    "            newline = True ) # progress bar to display current stage in training\n",
    "    for i,train_batch in enumerate(train_loader): # iterating through dataloader\n",
    "        gad_images = train_batch['image'].cuda()# gad images of batch\n",
    "        nongad_images = train_batch['label'].cuda() # nongad images of batch\n",
    "        #print(gad_images.shape)\n",
    "        cnn_opt.zero_grad()\n",
    "        degad_images = CNN_model(gad_images) # feeding CNN with gad images\n",
    "        train_loss= mean_abs_error(degad_images, nongad_images)\n",
    "        train_loss.backward()\n",
    "        cnn_opt.step()\n",
    "        epoch_loss += train_loss.item() # adding loss for this batch to the total training loss for this epoch\n",
    "    avg_training_loss = epoch_loss / training_steps\n",
    "    epoch_loss_values.append(avg_training_loss) # append total epoch loss divided by the number of training steps in epoch to loss list\n",
    "    CNN_model.eval() #setting model to evaluation mode for validation\n",
    "    with torch.no_grad(): #we do not update weights/biases in validation training, only used to assess current state of model\n",
    "        mae_total_epoch = 0 # mean squared error for the entire epoch\n",
    "        for i,val_batch in enumerate(val_loader): # iterating through dataloader\n",
    "            gad_images =val_batch[\"image\"].cuda()# batch with gad images\n",
    "            nongad_images = val_batch[\"label\"].cuda() # batch with nongad images\n",
    "            degad_images = CNN_model(gad_images)\n",
    "            val_loss = mean_abs_error(degad_images, nongad_images)\n",
    "            mae_total_epoch += val_loss # adding val mse of this batch to total val epoch mse\n",
    "        avg_val_mae = mae_total_epoch.item()/validation_steps\n",
    "        mae_val.append(avg_val_mae) # dividing total mse in this epoch by the number of batches -> add to list of epoch mse\n",
    "        early_stopping(avg_val_mae, CNN_model) # early stopping is based on the average validation mse for an epoch, keeps track of last best model\n",
    "        \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\") # stops early if validation mae has not improved for 10 epochs\n",
    "        break\n",
    "\n",
    "end = time.time()\n",
    "time = end - start\n",
    "print(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/model_stats.txt', 'w') as file:  \n",
    "    file.write(f'training time: {time}\\n')  \n",
    "    file.write(f'training loss: {epoch_loss_values[-1]} validation loss: {mae_val[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy('/home/fogunsan/scratch/degad/repo/MRI-DeGad/src/6a-train_degad_CNN.py', f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/')\n",
    "# copy current version of training script to folder date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.semilogy(list(range(len(epoch_loss_values))), epoch_loss_values, label=\"Training Loss\")\n",
    "plt.semilogy(list(range(len(mae_val))), mae_val , label=\"Validation Loss\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "plt.savefig(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/lossfunction.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.load_state_dict(torch.load(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/checkpoint.pt'))\n",
    "CNN_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running inference on only one test subject\n",
    "inference_transforms = Compose( #loading full image\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityd(keys = [\"image\"], minv=0.0, maxv=1.0)])# applying min max normalization only on gad images\n",
    "        \n",
    "\n",
    "infer_ds = Dataset(data=test_files[0], transform=inference_transforms) \n",
    "infer_loader = DataLoader(infer_ds, batch_size=1, shuffle=True) #using pytorch's dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degad_imgs = []\n",
    "gad_infer_imgs = []\n",
    "nongad_infer_imgs = []\n",
    "for infer_imgs in infer_loader:\n",
    "    gad_infer_imgs.append(infer_imgs[\"image\"])\n",
    "    nongad_infer_imgs.append(infer_imgs[\"label\"])\n",
    "    output_degad_img = sliding_window_inference(inputs = infer_imgs[\"image\"].to('cpu'), roi_size = (32,32,32), sw_batch_size= 5, predictor = CNN_model.to('cuda'), overlap = 0.25, mode = \"gaussian\", sw_device= 'cuda', device = 'cpu', progress = True )\n",
    "    degad_imgs.append(output_degad_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(degad_imgs)): #looping thru number of output files\n",
    "    degad_img =degad_imgs[i][0][0] # reshaping to exclude batch and channels (only one channel)\n",
    "    gad_image= nibabel.load(test_files[i][\"image\"]) # getting original gad image back to compare to \n",
    "    gad_image_file = test_files[i][\"image\"]\n",
    "    print(gad_image_file)\n",
    "    sub = os.path.basename(gad_image_file).split(\"_\")[0]\n",
    "    degad_name = f'{sub}_acq-degad_T1w.nii.gz'\n",
    "    degad_file = nibabel.Nifti1Image(degad_img.detach().numpy(), affine= None,header= gad_image.header) # with same header as inference gad \n",
    "    output_dir = f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/test'\n",
    "    os.makedirs(f'{output_dir}/bids/{sub}/ses-pre/anat', exist_ok=True)# save in bids format\n",
    "    output_path = f'{output_dir}/bids/{sub}/ses-pre/anat/{degad_name}'\n",
    "    nibabel.save(degad_file,output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "## generating random whole brain slices\n",
    "fig, axes = plt.subplots(8, 3,figsize=(10,25))\n",
    "plt.suptitle('Whole brain slices: Gad, NonGad, Degad')\n",
    "\n",
    "for i in range (1,25,3):\n",
    "    plt.subplot(8, 3, i)\n",
    "    x = random.randint(80, 190)\n",
    "    plt.imshow(gad_infer_imgs[0][0, 0,40:210 ,40:150, x].cpu().data.numpy(), cmap =\"gray\")\n",
    "    \n",
    "    plt.subplot(8, 3, i+1)\n",
    "    plt.imshow(nongad_infer_imgs[0][0, 0, 40:210 , 40:150, x].cpu().data.numpy(), \"gray\")\n",
    "    \n",
    "    plt.subplot(8, 3, i+2)\n",
    "    plt.imshow(degad_imgs[0][0, 0, 40:210,40:150, x].cpu().data.numpy(), \"gray\")\n",
    "\n",
    "plt.savefig(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/test/figure_whole_brain.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating random 32x32 slices\n",
    "fig, axes = plt.subplots(8, 4,figsize=(10,20))\n",
    "plt.suptitle('Whole brain slices: Gad, NonGad, Degad')\n",
    "\n",
    "for i in range (1,25,3):\n",
    "    \n",
    "    x = random.randint(40, 190)\n",
    "    y = random.randint(40, 190)\n",
    "    z = random.randint(40, 190)\n",
    "    plt.subplot(8, 3, i)\n",
    "    plt.imshow(gad_infer_imgs[0][0, 0, x:x+32,y:y+32 ,50].cpu().data.numpy(), cmap =\"gray\")\n",
    "    plt.subplot(8, 3, i+1)\n",
    "    plt.imshow(nongad_infer_imgs[0][0, 0, x:x+32,y:y+32 ,50].cpu().data.numpy(), \"gray\")\n",
    "    plt.subplot(8, 3, i+2)\n",
    "    plt.imshow(degad_imgs[0][0, 0, x:x+32,y:y+32,50].cpu().data.numpy(), \"gray\")\n",
    "   \n",
    "\n",
    "plt.savefig(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/test/figure_32_patches.png')  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
