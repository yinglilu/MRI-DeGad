{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/fogunsan.9485230.0/tmp/kslurm-venv-kc5y0uf6/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "import shutil\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    Spacingd,\n",
    "    RandWeightedCrop,\n",
    "    RandRotate,\n",
    "    RandFlip,\n",
    "    Rand3DElasticd,\n",
    "    Rand3DElastic,\n",
    "    RandRotated,\n",
    "    LoadImage,\n",
    "    EnsureChannelFirstd,\n",
    "    Orientationd,\n",
    "    EnsureChannelFirst,\n",
    "    ScaleIntensityd,\n",
    "    RandFlip,\n",
    "    ToTensor,\n",
    "    SpatialPadd,\n",
    "    ToTensord,\n",
    "    ScaleIntensity,\n",
    "    RandFlipd)\n",
    "import nibabel\n",
    "import shutil\n",
    "import tqdm\n",
    "from torchmetrics import MeanSquaredError\n",
    "import time\n",
    "from monai.networks.nets import UNet\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, Dataset ,nifti_saver, PatchDataset, PersistentDataset, SmartCacheDataset, ThreadDataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import nibabel\n",
    "from glob import glob\n",
    "from monai.networks.blocks import Convolution\n",
    "from monai.networks.nets import Discriminator, Generator\n",
    "from monai.utils import progress_bar\n",
    "import torch.nn as nn\n",
    "import torchmetrics \n",
    "from pytorchtools import EarlyStopping\n",
    "import numpy \n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure as SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=\"test\"#  put current date if training, test if just testing\n",
    "\n",
    "if not os.path.exists(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}'):\n",
    "    os.makedirs(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}')\n",
    "    \n",
    "if date != \"test\":\n",
    "    shutil.copy('/home/fogunsan/scratch/degad/repo/MRI-DeGad/src/9a-train_degad_CNN_c3d_32.py', f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_tr='/localscratch/tmp/training_samples_31.dat'\n",
    "                        # Patch dimensions\n",
    "\n",
    "patch_radius= numpy.array([15,15,15])\n",
    "dims = 1+2*patch_radius \n",
    "dims = dims.astype('int')\n",
    "\n",
    "k = 2                                 # Number of channels\n",
    "bps = (4 * k * numpy.prod(dims))    # Bytes per sample\n",
    "np_tr = os.path.getsize(fname_tr) // bps      # Number of samples\n",
    "\n",
    "arr_shape_tr= (int(np_tr),dims[0],dims[1],dims[2], k)\n",
    "\n",
    "arr_train = numpy.memmap(fname_tr,'float32','r+',shape=arr_shape_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_va='/localscratch/tmp/validation_samples_31.dat'\n",
    "                        # Patch dimensions\n",
    "\n",
    "np_va = os.path.getsize(fname_va) // bps      # Number of samples\n",
    "\n",
    "arr_shape_va= (int(np_va),dims[0],dims[1],dims[2], k)\n",
    "\n",
    "arr_val= numpy.memmap(fname_va,'float32','r+',shape=arr_shape_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train = numpy.swapaxes(arr_train,1,4)\n",
    "arr_val = numpy.swapaxes(arr_val,1,4)\n",
    "train_size=500\n",
    "#train_size=int(arr_train.shape[0])\n",
    "\n",
    "val_size=500\n",
    "#val_size=int(arr_val.shape[0]) # reduced size to accelerate training\n",
    "arr_train_image = arr_train[0:train_size,0,:,:,:].reshape(train_size,1,arr_train.shape[2],arr_train.shape[3],arr_train.shape[4])\n",
    "arr_train_label = arr_train[0:train_size,1,:,:,:].reshape(train_size,1,arr_train.shape[2],arr_train.shape[3],arr_train.shape[4])\n",
    "\n",
    "arr_val_image = arr_val[0:val_size,0,:,:,:].reshape(val_size,1, arr_val.shape[2],arr_val.shape[3],arr_val.shape[4])\n",
    "arr_val_label = arr_val[0:val_size,1,:,:,:].reshape(val_size,1, arr_val.shape[2],arr_val.shape[3],arr_val.shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_dict= [{\"image\": gad_name, \"label\": nongad_name} for gad_name, nongad_name in zip(arr_train_image,arr_train_label)]\n",
    "arr_val_dict= [{\"image\": gad_name, \"label\": nongad_name} for gad_name, nongad_name in zip(arr_val_image,arr_val_label)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([SpatialPadd(keys = (\"image\",\"label\"), spatial_size = (32,32,32)), Rand3DElasticd(keys = (\"image\",\"label\"), sigma_range = (0.5,1), magnitude_range = (0.1, 0.4), prob=0.4, shear_range=(0.1, -0.05, 0.0, 0.0, 0.0, 0.0), scale_range=0.5, padding_mode= \"zeros\"),\n",
    "          RandFlipd(keys = (\"image\",\"label\"), prob = 0.5, spatial_axis=1),RandFlipd(keys = (\"image\",\"label\"), prob = 0.5, spatial_axis=0),RandFlipd(keys = (\"image\",\"label\"), prob = 0.5, spatial_axis=2)])\n",
    "val_transforms = Compose([SpatialPadd(keys = (\"image\",\"label\"),spatial_size = (32,32,32))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 500/500 [00:02<00:00, 213.63it/s]\n",
      "Loading dataset: 100%|██████████| 500/500 [00:02<00:00, 217.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_patches_dataset = CacheDataset(data=arr_train_dict ,transform = train_transforms, cache_rate =1.0, copy_cache=False, progress=True) # dataset with cache mechanism that can load data and cache deterministic transforms’ result during training.\n",
    "validate_patches_dataset = CacheDataset(data=arr_val_dict ,transform = val_transforms, cache_rate = 1.0, copy_cache=False,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(32, 64, 128, 256, 512, 1024, 1024, 1024),\n",
    "    strides=(2, 2, 2, 2, 1, 1, 1),\n",
    "    dropout=0.2,\n",
    "    norm='BATCH'\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "CNN.apply(monai.networks.normal_init)\n",
    "CNN_model = CNN.to(device)\n",
    "trainable_params = sum(p.numel() for p in CNN_model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # changed back to 64\n",
    "training_steps = int(np_tr / batch_size) # number of training steps per epoch\n",
    "validation_steps = int(np_va / batch_size) # number of validation steps per epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_patches_dataset, batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "val_loader = DataLoader(validate_patches_dataset, batch_size=batch_size, shuffle=True,num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "learning_rate = 1e-4 # multiplied 2e-5*5\n",
    "betas = (0.5, 0.999)\n",
    "cnn_opt = torch.optim.Adam(CNN_model.parameters(), lr = learning_rate, betas=betas)\n",
    "patience = 100# epochs it will take for training to terminate if no improvement\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True, path = f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/checkpoint.pt')\n",
    "start = time.time() # initializing variable to calculate training time\n",
    "\n",
    "max_epochs = 4000 # max total iterations over entire training set\n",
    "#root_mean_squared = MeanSquaredError(squared = False).to(device) #rmse metric calculated at the end of each epoch for training and val\n",
    "mean_abs_error = torch.nn.L1Loss().to(device)\n",
    "#SSIM_L = SSIM(gaussian_kernel=True, sigma=1.5, reduction='elementwise_mean').to(device)\n",
    "\n",
    "mae_val = [0] # list of validation loss calculated at the end of each epoch\n",
    "epoch_loss_values = [0] # list of training loss calculated at the end of each epoch\n",
    "\n",
    "#train_loader = DataLoader(train_patches_dataset, batch_size=batch_size, shuffle=True, num_workers = 16)\n",
    "#val_loader = DataLoader(validate_patches_dataset, batch_size=batch_size, shuffle=True, num_workers =16)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    CNN_model.train() # setting model to training mode\n",
    "    epoch_loss = 0 # total traininig loss in an epoch\n",
    "    progress_bar(\n",
    "            index=epoch+1, # displays what step we are of current epoch, our epoch number, training  loss\n",
    "            count = max_epochs, \n",
    "            desc= f\"epoch {epoch + 1}, training mae loss: {epoch_loss_values[-1]:.4f}, validation mae metric: {mae_val[-1]:.4f}\",\n",
    "            newline = True) # progress bar to display current stage in training\n",
    "   \n",
    "    for i,train_batch in enumerate(train_loader): # iterating through dataloader\n",
    "        gad_images =train_batch[\"image\"].cuda()# batch with gad images\n",
    "        nongad_images = train_batch[\"label\"].cuda() # batch with nongad images\n",
    "        #plt.subplot(2, 1, 1)\n",
    "        #plt.imshow(gad_images[0, 0,: ,:, 20].cpu().data.numpy(), cmap =\"gray\")\n",
    "        #plt.subplot(2, 1, 2)\n",
    "        cnn_opt.zero_grad()\n",
    "        degad_images = CNN_model(gad_images) # feeding CNN with gad images\n",
    "        #MAE_loss = mean_abs_error(degad_images, nongad_images)\n",
    "        #SSIM_loss = 1- SSIM_L(degad_images, nongad_images) # want to maximize SSIM loss so subtract from 1\n",
    "        #train_loss= 0.5*MAE_loss + 0.35*SSIM_loss\n",
    "        train_loss = mean_abs_error(degad_images, nongad_images)\n",
    "        train_loss.backward()\n",
    "        cnn_opt.step()\n",
    "        epoch_loss += train_loss.item() # adding loss for this batch to the total training loss for this epoch\n",
    "    avg_training_loss = epoch_loss / training_steps\n",
    "    epoch_loss_values.append(avg_training_loss) # append total epoch loss divided by the number of training steps in epoch to loss list\n",
    "    CNN_model.eval() #setting model to evaluation mode for validation\n",
    "    with torch.no_grad(): #we do not update weights/biases in validation training, only used to assess current state of model\n",
    "        mae_total_epoch = 0 # mean absolute error for the entire epoch\n",
    "        for i,val_batch in enumerate(val_loader): # iterating through dataloader\n",
    "            gad_images =val_batch[\"image\"].cuda()# batch with gad images\n",
    "            nongad_images = val_batch[\"label\"].cuda() # batch with nongad images\n",
    "            degad_images = CNN_model(gad_images)\n",
    "            #MAE_loss = mean_abs_error(degad_images, nongad_images)\n",
    "            #SSIM_loss = 1- SSIM_L(degad_images, nongad_images)\n",
    "            #val_loss= 0.5*MAE_loss + 0.35*SSIM_loss\n",
    "            val_loss = mean_abs_error(degad_images, nongad_images)\n",
    "            mae_total_epoch += val_loss # adding val mse of this batch to total val epoch mse\n",
    "        avg_val_mae = mae_total_epoch.item()/validation_steps\n",
    "        mae_val.append(avg_val_mae) # dividing total mse in this epoch by the number of batches -> add to list of epoch mse\n",
    "        early_stopping(avg_val_mae, CNN_model) # early stopping is based on the average validation mse for an epoch, keeps track of last best model\n",
    "        \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\") # stops early if validation mae has not improved for 100 epochs\n",
    "        break\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "time = end - start\n",
    "print(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/model_stats.txt', 'w') as file:  \n",
    "    file.write(f'Training time: {time}\\n') \n",
    "    file.write(f'Number of trainable parameters: {trainable_params}')\n",
    "    file.write(f'Training loss: {epoch_loss_values[-patience]} Validation loss: {early_stopping.val_loss_min}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(list(range(len(epoch_loss_values))), epoch_loss_values, label=\"Training Loss\")\n",
    "plt.plot(list(range(len(mae_val))), mae_val , label=\"Validation Loss\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "plt.savefig(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/lossfunction.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.load_state_dict(torch.load(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/checkpoint.pt'))\n",
    "CNN_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running inference \n",
    "test_gad_t1= sorted(glob('/project/6050199/akhanf/cfmm-bids/data/Lau/degad/derivatives/passing_dataset/sub-P*/*rescaled_T1w.nii.gz'))[-1:]\n",
    "# gad images who's corresponding nongad images underwent a rigid transform\n",
    "test_nongad_t1= sorted(glob('/project/6050199/akhanf/cfmm-bids/data/Lau/degad/derivatives/passing_dataset/sub-P*/*nongad_normalized_fcm.nii.gz'))[-1:] # nongad images which underwent a rigid transform and underwent fcm normalization\n",
    "test_files = [{\"image\": gad_name, \"label\": nongad_name} for gad_name, nongad_name in zip(test_gad_t1,test_nongad_t1)] #creates list of dictionaries, with gad and nongad images labelled\n",
    "\n",
    "\n",
    "inference_transforms = Compose( #loading full image\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"])])\n",
    "        \n",
    "\n",
    "infer_ds = Dataset(data=test_files, transform=inference_transforms) \n",
    "infer_loader = DataLoader(infer_ds, batch_size=1, shuffle=True) #using pytorch's dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degad_imgs = []\n",
    "gad_infer_imgs = []\n",
    "nongad_infer_imgs = []\n",
    "for infer_imgs in infer_loader:\n",
    "    gad_infer_imgs.append(infer_imgs[\"image\"])\n",
    "    nongad_infer_imgs.append(infer_imgs[\"label\"])\n",
    "    output_degad_img = sliding_window_inference(inputs = infer_imgs[\"image\"].to('cpu'), roi_size = (32,32,32), sw_batch_size= 5, predictor = CNN_model.to('cpu'), overlap = 0.25, mode = \"gaussian\", sw_device= 'cpu', device = 'cpu', progress = True )\n",
    "    degad_imgs.append(output_degad_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(degad_imgs)): #looping thru number of output files\n",
    "    degad_img =degad_imgs[i][0][0] # reshaping to exclude batch and channels (only one channel)\n",
    "    gad_image= nibabel.load(test_files[i][\"image\"]) # getting original gad image back to compare to \n",
    "    gad_image_file = test_files[i][\"image\"]\n",
    "    print(gad_image_file)\n",
    "    sub = os.path.basename(gad_image_file).split(\"_\")[0]\n",
    "    degad_name = f'{sub}_acq-degad_T1w.nii.gz'\n",
    "    degad_file = nibabel.Nifti1Image(degad_img.detach().numpy()*100, affine= gad_image.affine,header= gad_image.header) # with same header as inference gad \n",
    "    output_dir = f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/test'\n",
    "    os.makedirs(f'{output_dir}/bids/{sub}/ses-pre/anat', exist_ok=True)# save in bids format\n",
    "    output_path = f'{output_dir}/bids/{sub}/ses-pre/anat/{degad_name}'\n",
    "    nibabel.save(degad_file,output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "## generating random whole brain slices\n",
    "fig, axes = plt.subplots(8, 4,figsize=(10,25))\n",
    "plt.suptitle('Whole brain slices: Gad, NonGad, Degad, subtraction map')\n",
    "\n",
    "for i in range (1,33,4):\n",
    "    plt.subplot(8, 4, i)\n",
    "    x = random.randint(80, 190)\n",
    "    plt.imshow(gad_infer_imgs[0][0, 0,40:210 ,40:150, x].cpu().data.numpy(), cmap =\"gray\")\n",
    "    \n",
    "    plt.subplot(8, 4, i+1)\n",
    "    plt.imshow(nongad_infer_imgs[0][0, 0, 40:210 , 40:150, x].cpu().data.numpy(), \"gray\")\n",
    "    \n",
    "    plt.subplot(8, 4, i+2)\n",
    "    plt.imshow(degad_imgs[0][0, 0, 40:210,40:150, x].cpu().data.numpy(), \"gray\")\n",
    "    \n",
    "    plt.subplot(8, 4, i+3)\n",
    "    noise_vector = degad_imgs[0][0,0,:,:,:] - nongad_infer_imgs[0][0,0,:,:,:] \n",
    "    #pos values are where model overestimated intensities and neg values are where the model underestimated\n",
    "    plt.imshow(noise_vector[40:210,40:150, x].cpu().data.numpy(), \"seismic\",vmin=-1,vmax=1)\n",
    "    plt.colorbar()\n",
    "plt.savefig(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/test/figure_whole_brain.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating random 32x32 slices\n",
    "fig, axes = plt.subplots(8, 4,figsize=(10,20))\n",
    "plt.suptitle('Patches: Gad, NonGad, Degad, subtraction map')\n",
    "\n",
    "for i in range (1,33,4):\n",
    "    \n",
    "    x = random.randint(40, 190)\n",
    "    y = random.randint(40, 190)\n",
    "    z = random.randint(40, 190)\n",
    "    plt.subplot(8, 4, i)\n",
    "    plt.imshow(gad_infer_imgs[0][0, 0, x:x+32,y:y+32 ,50].cpu().data.numpy(), cmap =\"gray\")\n",
    "    plt.subplot(8, 4, i+1)\n",
    "    plt.imshow(nongad_infer_imgs[0][0, 0, x:x+32,y:y+32 ,50].cpu().data.numpy(), \"gray\")\n",
    "    plt.subplot(8, 4, i+2)\n",
    "    plt.imshow(degad_imgs[0][0, 0, x:x+32,y:y+32,50].cpu().data.numpy(), \"gray\")\n",
    "    plt.subplot(8, 4, i+3)\n",
    "    noise_vector = degad_imgs[0][0,0,:,:,:] - nongad_infer_imgs[0][0,0,:,:,:] \n",
    "    #pos values are where model overestimated intensities and neg values are where the model underestimated\n",
    "    plt.imshow(noise_vector[40:210,40:150, x].cpu().data.numpy(), \"seismic\",vmin=-1,vmax=1)\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.savefig(f'/home/fogunsan/scratch/degad/derivatives/UNET/{date}/test/figure_32_patches.png')  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
